{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2bd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d18b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983709aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=5\n",
    "img_rows,img_cols=48,48\n",
    "batch_size=8\n",
    "\n",
    "train_data_dir=r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\training_data'\n",
    "validation_data_dir=r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\validation_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf0f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=30,shear_range=0.3,\n",
    "                                 zoom_range=30,width_shift_range=0.4,height_shift_range=0.4,\n",
    "                                 horizontal_flip=True,vertical_flip=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceeea6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192496a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24282 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generstor=train_datagen.flow_from_directory(r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\train/',color_mode='grayscale',class_mode='categorical',\n",
    "                                                 shuffle=True,target_size=(img_rows,img_cols),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788ec92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5937 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generstor=validation_datagen.flow_from_directory(r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\validation/',color_mode='grayscale',class_mode='categorical',\n",
    "                                                 shuffle=True,target_size=(img_rows,img_cols),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedcff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ffc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block1\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f006fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block2\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d7034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block3\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b639bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block4\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c9ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71350c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block6\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9936ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block7\n",
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b11590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 12, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 12, 12, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                147520    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,328,037\n",
      "Trainable params: 1,325,861\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b60d55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955c7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=ModelCheckpoint(r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\Emotion_little_vgg.h5',\n",
    "                          monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          save_best_only=True,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e54efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop=EarlyStopping(monitor='val_loss',\n",
    "                       min_delta=0,\n",
    "                       patience=3,\n",
    "                       verbose=1,\n",
    "                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4127a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss',\n",
    "                           factor=0.2,\n",
    "                           patience=3,\n",
    "                           verbose=1,\n",
    "                           min_delta=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a183e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[earlystop,checkpoint,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23925ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1f55c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples=24282\n",
    "nb_validation_samples=5937\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d578504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - ETA: 0s - loss: 1.7485 - accuracy: 0.2464\n",
      "Epoch 1: val_loss improved from inf to 1.56710, saving model to C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\Emotion_little_vgg.h5\n",
      "3035/3035 [==============================] - 537s 175ms/step - loss: 1.7485 - accuracy: 0.2464 - val_loss: 1.5671 - val_accuracy: 0.3037 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_generstor,\n",
    "                           steps_per_epoch=nb_train_samples//batch_size,\n",
    "                           epochs=epochs,\n",
    "                           callbacks=callbacks,\n",
    "                           validation_data=validation_generstor,\n",
    "                            validation_steps=nb_validation_samples//batch_size\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38e229",
   "metadata": {},
   "source": [
    "#Challange\n",
    "- Facial Expresion using Image \n",
    "\n",
    "#Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ffb978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 354ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier=cv2.CascadeClassifier(r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\Facial.xml')\n",
    "model=load_model(r'C:\\Users\\Lenovo\\Downloads\\Facial Recognization\\face-expression-recognition-dataset\\Emotion_little_vgg.h5')\n",
    "\n",
    "class_label=['Angry','Happy','Sad','Neutral','Surprise']\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi=roi_gray.astype('float')/255.0\n",
    "            roi=img_to_array(roi)\n",
    "            \n",
    "            roi=np.expand_dims(roi,axis=0)\n",
    "            \n",
    "            preds=model.predict(roi)[0]\n",
    "            label=class_label[preds.argmax()]\n",
    "            label_position=(x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,2,(0,255,0),3)\n",
    "            \n",
    "        else:\n",
    "            cv2.putText(frame,'No Face Found',(20,60),cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,2,(0,255,0),3)\n",
    "                \n",
    "                \n",
    "    cv2.imshow('Emotion Dectector',frame)\n",
    "    if cv2.waitKey(1):\n",
    "        break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
